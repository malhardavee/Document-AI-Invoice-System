{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8280,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018115942028985508,
      "grad_norm": 0.041119929403066635,
      "learning_rate": 4.970410628019324e-05,
      "loss": 0.0657,
      "step": 50
    },
    {
      "epoch": 0.036231884057971016,
      "grad_norm": 0.06687091290950775,
      "learning_rate": 4.9402173913043484e-05,
      "loss": 0.0094,
      "step": 100
    },
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 0.09362130612134933,
      "learning_rate": 4.910024154589372e-05,
      "loss": 0.01,
      "step": 150
    },
    {
      "epoch": 0.07246376811594203,
      "grad_norm": 0.04408600553870201,
      "learning_rate": 4.8798309178743963e-05,
      "loss": 0.0115,
      "step": 200
    },
    {
      "epoch": 0.09057971014492754,
      "grad_norm": 0.08299475163221359,
      "learning_rate": 4.8496376811594207e-05,
      "loss": 0.01,
      "step": 250
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 0.06344008445739746,
      "learning_rate": 4.819444444444445e-05,
      "loss": 0.0109,
      "step": 300
    },
    {
      "epoch": 0.12681159420289856,
      "grad_norm": 0.053558941930532455,
      "learning_rate": 4.7892512077294686e-05,
      "loss": 0.0098,
      "step": 350
    },
    {
      "epoch": 0.14492753623188406,
      "grad_norm": 0.052719391882419586,
      "learning_rate": 4.759057971014493e-05,
      "loss": 0.0055,
      "step": 400
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 0.02054448053240776,
      "learning_rate": 4.728864734299517e-05,
      "loss": 0.0095,
      "step": 450
    },
    {
      "epoch": 0.18115942028985507,
      "grad_norm": 0.088227778673172,
      "learning_rate": 4.6986714975845415e-05,
      "loss": 0.0091,
      "step": 500
    },
    {
      "epoch": 0.19927536231884058,
      "grad_norm": 0.07030513137578964,
      "learning_rate": 4.668478260869565e-05,
      "loss": 0.0079,
      "step": 550
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 0.0918029323220253,
      "learning_rate": 4.6382850241545895e-05,
      "loss": 0.0075,
      "step": 600
    },
    {
      "epoch": 0.23550724637681159,
      "grad_norm": 0.04331143572926521,
      "learning_rate": 4.608091787439614e-05,
      "loss": 0.0069,
      "step": 650
    },
    {
      "epoch": 0.2536231884057971,
      "grad_norm": 0.05243534594774246,
      "learning_rate": 4.577898550724638e-05,
      "loss": 0.0071,
      "step": 700
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 0.0823262631893158,
      "learning_rate": 4.5477053140096624e-05,
      "loss": 0.006,
      "step": 750
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 0.07592969387769699,
      "learning_rate": 4.517512077294686e-05,
      "loss": 0.0072,
      "step": 800
    },
    {
      "epoch": 0.3079710144927536,
      "grad_norm": 0.05862107500433922,
      "learning_rate": 4.48731884057971e-05,
      "loss": 0.0064,
      "step": 850
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 0.04923108220100403,
      "learning_rate": 4.4571256038647346e-05,
      "loss": 0.0102,
      "step": 900
    },
    {
      "epoch": 0.3442028985507246,
      "grad_norm": 0.08448412269353867,
      "learning_rate": 4.426932367149759e-05,
      "loss": 0.0083,
      "step": 950
    },
    {
      "epoch": 0.36231884057971014,
      "grad_norm": 0.05901908129453659,
      "learning_rate": 4.3967391304347826e-05,
      "loss": 0.0079,
      "step": 1000
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 0.09524034708738327,
      "learning_rate": 4.366545893719807e-05,
      "loss": 0.0075,
      "step": 1050
    },
    {
      "epoch": 0.39855072463768115,
      "grad_norm": 0.07913842052221298,
      "learning_rate": 4.336352657004831e-05,
      "loss": 0.0073,
      "step": 1100
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.09321658313274384,
      "learning_rate": 4.3061594202898555e-05,
      "loss": 0.0056,
      "step": 1150
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.03544090688228607,
      "learning_rate": 4.275966183574879e-05,
      "loss": 0.0078,
      "step": 1200
    },
    {
      "epoch": 0.4528985507246377,
      "grad_norm": 0.23617804050445557,
      "learning_rate": 4.2457729468599034e-05,
      "loss": 0.0064,
      "step": 1250
    },
    {
      "epoch": 0.47101449275362317,
      "grad_norm": 0.1401609480381012,
      "learning_rate": 4.215579710144928e-05,
      "loss": 0.0071,
      "step": 1300
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 0.1113811805844307,
      "learning_rate": 4.185386473429952e-05,
      "loss": 0.0073,
      "step": 1350
    },
    {
      "epoch": 0.5072463768115942,
      "grad_norm": 0.062780000269413,
      "learning_rate": 4.155193236714976e-05,
      "loss": 0.0065,
      "step": 1400
    },
    {
      "epoch": 0.5253623188405797,
      "grad_norm": 0.06766310334205627,
      "learning_rate": 4.125e-05,
      "loss": 0.0076,
      "step": 1450
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 0.04783365875482559,
      "learning_rate": 4.094806763285024e-05,
      "loss": 0.0097,
      "step": 1500
    },
    {
      "epoch": 0.5615942028985508,
      "grad_norm": 0.05570366606116295,
      "learning_rate": 4.0646135265700486e-05,
      "loss": 0.0077,
      "step": 1550
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.010255983099341393,
      "learning_rate": 4.034420289855073e-05,
      "loss": 0.0054,
      "step": 1600
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 0.013986977748572826,
      "learning_rate": 4.0042270531400965e-05,
      "loss": 0.0066,
      "step": 1650
    },
    {
      "epoch": 0.6159420289855072,
      "grad_norm": 0.15006965398788452,
      "learning_rate": 3.9740338164251215e-05,
      "loss": 0.0061,
      "step": 1700
    },
    {
      "epoch": 0.6340579710144928,
      "grad_norm": 0.06672674417495728,
      "learning_rate": 3.943840579710145e-05,
      "loss": 0.0064,
      "step": 1750
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 0.0031424330081790686,
      "learning_rate": 3.9136473429951695e-05,
      "loss": 0.0057,
      "step": 1800
    },
    {
      "epoch": 0.6702898550724637,
      "grad_norm": 0.015163911506533623,
      "learning_rate": 3.883454106280193e-05,
      "loss": 0.0072,
      "step": 1850
    },
    {
      "epoch": 0.6884057971014492,
      "grad_norm": 0.018236586824059486,
      "learning_rate": 3.853260869565218e-05,
      "loss": 0.0064,
      "step": 1900
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 0.03914486616849899,
      "learning_rate": 3.823067632850242e-05,
      "loss": 0.0057,
      "step": 1950
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.07002115994691849,
      "learning_rate": 3.792874396135266e-05,
      "loss": 0.0071,
      "step": 2000
    },
    {
      "epoch": 0.7427536231884058,
      "grad_norm": 0.03834301605820656,
      "learning_rate": 3.7626811594202896e-05,
      "loss": 0.0067,
      "step": 2050
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 0.0016819543670862913,
      "learning_rate": 3.7324879227053146e-05,
      "loss": 0.0051,
      "step": 2100
    },
    {
      "epoch": 0.7789855072463768,
      "grad_norm": 0.006661843974143267,
      "learning_rate": 3.702294685990338e-05,
      "loss": 0.0076,
      "step": 2150
    },
    {
      "epoch": 0.7971014492753623,
      "grad_norm": 0.047056399285793304,
      "learning_rate": 3.6721014492753626e-05,
      "loss": 0.0061,
      "step": 2200
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 0.03449717164039612,
      "learning_rate": 3.641908212560386e-05,
      "loss": 0.0051,
      "step": 2250
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.03834886476397514,
      "learning_rate": 3.611714975845411e-05,
      "loss": 0.0064,
      "step": 2300
    },
    {
      "epoch": 0.8514492753623188,
      "grad_norm": 0.004781278781592846,
      "learning_rate": 3.581521739130435e-05,
      "loss": 0.0043,
      "step": 2350
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.06774115562438965,
      "learning_rate": 3.551328502415459e-05,
      "loss": 0.0061,
      "step": 2400
    },
    {
      "epoch": 0.8876811594202898,
      "grad_norm": 0.008603581227362156,
      "learning_rate": 3.5211352657004834e-05,
      "loss": 0.0056,
      "step": 2450
    },
    {
      "epoch": 0.9057971014492754,
      "grad_norm": 0.0019013300770893693,
      "learning_rate": 3.490942028985507e-05,
      "loss": 0.0043,
      "step": 2500
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 0.006351588759571314,
      "learning_rate": 3.460748792270532e-05,
      "loss": 0.0056,
      "step": 2550
    },
    {
      "epoch": 0.9420289855072463,
      "grad_norm": 0.03464270383119583,
      "learning_rate": 3.430555555555556e-05,
      "loss": 0.0056,
      "step": 2600
    },
    {
      "epoch": 0.9601449275362319,
      "grad_norm": 0.10162334889173508,
      "learning_rate": 3.40036231884058e-05,
      "loss": 0.0077,
      "step": 2650
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 0.021926764398813248,
      "learning_rate": 3.3701690821256036e-05,
      "loss": 0.0063,
      "step": 2700
    },
    {
      "epoch": 0.9963768115942029,
      "grad_norm": 0.047185689210891724,
      "learning_rate": 3.3399758454106286e-05,
      "loss": 0.0052,
      "step": 2750
    },
    {
      "epoch": 1.0144927536231885,
      "grad_norm": 0.011050442233681679,
      "learning_rate": 3.309782608695652e-05,
      "loss": 0.0054,
      "step": 2800
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 0.05219472199678421,
      "learning_rate": 3.2795893719806765e-05,
      "loss": 0.0056,
      "step": 2850
    },
    {
      "epoch": 1.0507246376811594,
      "grad_norm": 0.07212687283754349,
      "learning_rate": 3.2493961352657e-05,
      "loss": 0.0049,
      "step": 2900
    },
    {
      "epoch": 1.068840579710145,
      "grad_norm": 0.02414066344499588,
      "learning_rate": 3.219202898550725e-05,
      "loss": 0.0057,
      "step": 2950
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.012079691514372826,
      "learning_rate": 3.189009661835749e-05,
      "loss": 0.0059,
      "step": 3000
    },
    {
      "epoch": 1.105072463768116,
      "grad_norm": 0.04073427617549896,
      "learning_rate": 3.158816425120773e-05,
      "loss": 0.0066,
      "step": 3050
    },
    {
      "epoch": 1.1231884057971016,
      "grad_norm": 0.1965477168560028,
      "learning_rate": 3.128623188405797e-05,
      "loss": 0.0077,
      "step": 3100
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 0.06279116123914719,
      "learning_rate": 3.098429951690822e-05,
      "loss": 0.0074,
      "step": 3150
    },
    {
      "epoch": 1.1594202898550725,
      "grad_norm": 0.058159470558166504,
      "learning_rate": 3.068236714975845e-05,
      "loss": 0.0068,
      "step": 3200
    },
    {
      "epoch": 1.177536231884058,
      "grad_norm": 0.13031724095344543,
      "learning_rate": 3.0380434782608696e-05,
      "loss": 0.0055,
      "step": 3250
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 0.0017233046237379313,
      "learning_rate": 3.0078502415458936e-05,
      "loss": 0.0055,
      "step": 3300
    },
    {
      "epoch": 1.213768115942029,
      "grad_norm": 0.027686940506100655,
      "learning_rate": 2.9776570048309183e-05,
      "loss": 0.0039,
      "step": 3350
    },
    {
      "epoch": 1.2318840579710144,
      "grad_norm": 0.024721695110201836,
      "learning_rate": 2.9474637681159422e-05,
      "loss": 0.0073,
      "step": 3400
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.035888612270355225,
      "learning_rate": 2.9172705314009662e-05,
      "loss": 0.0057,
      "step": 3450
    },
    {
      "epoch": 1.2681159420289856,
      "grad_norm": 0.03903091698884964,
      "learning_rate": 2.88707729468599e-05,
      "loss": 0.0034,
      "step": 3500
    },
    {
      "epoch": 1.286231884057971,
      "grad_norm": 0.00756825739517808,
      "learning_rate": 2.8568840579710148e-05,
      "loss": 0.0052,
      "step": 3550
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.04229961708188057,
      "learning_rate": 2.8266908212560388e-05,
      "loss": 0.0055,
      "step": 3600
    },
    {
      "epoch": 1.322463768115942,
      "grad_norm": 0.0006875912076793611,
      "learning_rate": 2.796497584541063e-05,
      "loss": 0.0066,
      "step": 3650
    },
    {
      "epoch": 1.3405797101449275,
      "grad_norm": 0.049454256892204285,
      "learning_rate": 2.766304347826087e-05,
      "loss": 0.0041,
      "step": 3700
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 0.04985330253839493,
      "learning_rate": 2.7361111111111114e-05,
      "loss": 0.0058,
      "step": 3750
    },
    {
      "epoch": 1.3768115942028984,
      "grad_norm": 0.10705851763486862,
      "learning_rate": 2.7059178743961357e-05,
      "loss": 0.0047,
      "step": 3800
    },
    {
      "epoch": 1.394927536231884,
      "grad_norm": 0.008944256231188774,
      "learning_rate": 2.6757246376811596e-05,
      "loss": 0.006,
      "step": 3850
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": 0.0006739033851772547,
      "learning_rate": 2.6455314009661836e-05,
      "loss": 0.0048,
      "step": 3900
    },
    {
      "epoch": 1.431159420289855,
      "grad_norm": 0.04030516743659973,
      "learning_rate": 2.6153381642512076e-05,
      "loss": 0.0055,
      "step": 3950
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 0.05703749135136604,
      "learning_rate": 2.5851449275362322e-05,
      "loss": 0.0054,
      "step": 4000
    },
    {
      "epoch": 1.4673913043478262,
      "grad_norm": 0.08024697750806808,
      "learning_rate": 2.5549516908212562e-05,
      "loss": 0.0067,
      "step": 4050
    },
    {
      "epoch": 1.4855072463768115,
      "grad_norm": 0.12308933585882187,
      "learning_rate": 2.52475845410628e-05,
      "loss": 0.0056,
      "step": 4100
    },
    {
      "epoch": 1.5036231884057971,
      "grad_norm": 0.3118661940097809,
      "learning_rate": 2.4945652173913045e-05,
      "loss": 0.007,
      "step": 4150
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 0.000608881819061935,
      "learning_rate": 2.4643719806763284e-05,
      "loss": 0.0039,
      "step": 4200
    },
    {
      "epoch": 1.539855072463768,
      "grad_norm": 0.045429762452840805,
      "learning_rate": 2.4341787439613527e-05,
      "loss": 0.0061,
      "step": 4250
    },
    {
      "epoch": 1.5579710144927537,
      "grad_norm": 0.0014113751240074635,
      "learning_rate": 2.4039855072463767e-05,
      "loss": 0.0047,
      "step": 4300
    },
    {
      "epoch": 1.5760869565217392,
      "grad_norm": 0.01907402090728283,
      "learning_rate": 2.373792270531401e-05,
      "loss": 0.0061,
      "step": 4350
    },
    {
      "epoch": 1.5942028985507246,
      "grad_norm": 0.25899991393089294,
      "learning_rate": 2.343599033816425e-05,
      "loss": 0.0061,
      "step": 4400
    },
    {
      "epoch": 1.6123188405797102,
      "grad_norm": 0.049305371940135956,
      "learning_rate": 2.3134057971014493e-05,
      "loss": 0.0064,
      "step": 4450
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": 0.0036012125201523304,
      "learning_rate": 2.2832125603864736e-05,
      "loss": 0.0053,
      "step": 4500
    },
    {
      "epoch": 1.6485507246376812,
      "grad_norm": 0.06188665330410004,
      "learning_rate": 2.253019323671498e-05,
      "loss": 0.0054,
      "step": 4550
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.05787109211087227,
      "learning_rate": 2.222826086956522e-05,
      "loss": 0.0044,
      "step": 4600
    },
    {
      "epoch": 1.6847826086956523,
      "grad_norm": 0.006406033877283335,
      "learning_rate": 2.1926328502415462e-05,
      "loss": 0.0036,
      "step": 4650
    },
    {
      "epoch": 1.7028985507246377,
      "grad_norm": 0.058475226163864136,
      "learning_rate": 2.16243961352657e-05,
      "loss": 0.0054,
      "step": 4700
    },
    {
      "epoch": 1.721014492753623,
      "grad_norm": 0.042054906487464905,
      "learning_rate": 2.1322463768115945e-05,
      "loss": 0.0057,
      "step": 4750
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.04230703413486481,
      "learning_rate": 2.1020531400966184e-05,
      "loss": 0.0049,
      "step": 4800
    },
    {
      "epoch": 1.7572463768115942,
      "grad_norm": 0.008985008113086224,
      "learning_rate": 2.0718599033816427e-05,
      "loss": 0.0058,
      "step": 4850
    },
    {
      "epoch": 1.7753623188405796,
      "grad_norm": 0.07626725733280182,
      "learning_rate": 2.0416666666666667e-05,
      "loss": 0.0041,
      "step": 4900
    },
    {
      "epoch": 1.7934782608695652,
      "grad_norm": 0.0028559851925820112,
      "learning_rate": 2.011473429951691e-05,
      "loss": 0.0039,
      "step": 4950
    },
    {
      "epoch": 1.8115942028985508,
      "grad_norm": 0.0030482967849820852,
      "learning_rate": 1.981280193236715e-05,
      "loss": 0.0046,
      "step": 5000
    },
    {
      "epoch": 1.8297101449275361,
      "grad_norm": 0.045664891600608826,
      "learning_rate": 1.9510869565217393e-05,
      "loss": 0.0045,
      "step": 5050
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": 0.0474008210003376,
      "learning_rate": 1.9208937198067633e-05,
      "loss": 0.0065,
      "step": 5100
    },
    {
      "epoch": 1.8659420289855073,
      "grad_norm": 0.1706935316324234,
      "learning_rate": 1.8907004830917876e-05,
      "loss": 0.0054,
      "step": 5150
    },
    {
      "epoch": 1.8840579710144927,
      "grad_norm": 0.08428429067134857,
      "learning_rate": 1.8605072463768115e-05,
      "loss": 0.0043,
      "step": 5200
    },
    {
      "epoch": 1.9021739130434783,
      "grad_norm": 0.0037721956614404917,
      "learning_rate": 1.830314009661836e-05,
      "loss": 0.0044,
      "step": 5250
    },
    {
      "epoch": 1.9202898550724639,
      "grad_norm": 0.00044767989311367273,
      "learning_rate": 1.8001207729468598e-05,
      "loss": 0.0053,
      "step": 5300
    },
    {
      "epoch": 1.9384057971014492,
      "grad_norm": 0.03986232355237007,
      "learning_rate": 1.769927536231884e-05,
      "loss": 0.0055,
      "step": 5350
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.03677956014871597,
      "learning_rate": 1.7397342995169084e-05,
      "loss": 0.0043,
      "step": 5400
    },
    {
      "epoch": 1.9746376811594204,
      "grad_norm": 0.16887865960597992,
      "learning_rate": 1.7095410628019324e-05,
      "loss": 0.004,
      "step": 5450
    },
    {
      "epoch": 1.9927536231884058,
      "grad_norm": 0.09693579375743866,
      "learning_rate": 1.6793478260869567e-05,
      "loss": 0.0068,
      "step": 5500
    },
    {
      "epoch": 2.010869565217391,
      "grad_norm": 0.04217872396111488,
      "learning_rate": 1.6491545893719807e-05,
      "loss": 0.0057,
      "step": 5550
    },
    {
      "epoch": 2.028985507246377,
      "grad_norm": 0.00915311835706234,
      "learning_rate": 1.618961352657005e-05,
      "loss": 0.0043,
      "step": 5600
    },
    {
      "epoch": 2.0471014492753623,
      "grad_norm": 0.03267345950007439,
      "learning_rate": 1.588768115942029e-05,
      "loss": 0.0044,
      "step": 5650
    },
    {
      "epoch": 2.0652173913043477,
      "grad_norm": 0.10731803625822067,
      "learning_rate": 1.5585748792270533e-05,
      "loss": 0.0041,
      "step": 5700
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.01412498950958252,
      "learning_rate": 1.5283816425120772e-05,
      "loss": 0.0058,
      "step": 5750
    },
    {
      "epoch": 2.101449275362319,
      "grad_norm": 0.06238871067762375,
      "learning_rate": 1.4981884057971015e-05,
      "loss": 0.0049,
      "step": 5800
    },
    {
      "epoch": 2.119565217391304,
      "grad_norm": 0.06994017213582993,
      "learning_rate": 1.4679951690821255e-05,
      "loss": 0.0045,
      "step": 5850
    },
    {
      "epoch": 2.13768115942029,
      "grad_norm": 0.053457461297512054,
      "learning_rate": 1.4378019323671498e-05,
      "loss": 0.0048,
      "step": 5900
    },
    {
      "epoch": 2.1557971014492754,
      "grad_norm": 0.004215277265757322,
      "learning_rate": 1.407608695652174e-05,
      "loss": 0.0044,
      "step": 5950
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.0003830082423519343,
      "learning_rate": 1.3774154589371983e-05,
      "loss": 0.0028,
      "step": 6000
    },
    {
      "epoch": 2.1920289855072466,
      "grad_norm": 0.0026672345120459795,
      "learning_rate": 1.3472222222222222e-05,
      "loss": 0.0032,
      "step": 6050
    },
    {
      "epoch": 2.210144927536232,
      "grad_norm": 0.020802849903702736,
      "learning_rate": 1.3170289855072465e-05,
      "loss": 0.0063,
      "step": 6100
    },
    {
      "epoch": 2.2282608695652173,
      "grad_norm": 0.05010315030813217,
      "learning_rate": 1.2868357487922705e-05,
      "loss": 0.0048,
      "step": 6150
    },
    {
      "epoch": 2.246376811594203,
      "grad_norm": 0.004396804608404636,
      "learning_rate": 1.2566425120772948e-05,
      "loss": 0.0052,
      "step": 6200
    },
    {
      "epoch": 2.2644927536231885,
      "grad_norm": 0.018632713705301285,
      "learning_rate": 1.2264492753623188e-05,
      "loss": 0.004,
      "step": 6250
    },
    {
      "epoch": 2.282608695652174,
      "grad_norm": 0.07799497991800308,
      "learning_rate": 1.196256038647343e-05,
      "loss": 0.0056,
      "step": 6300
    },
    {
      "epoch": 2.300724637681159,
      "grad_norm": 0.050104763358831406,
      "learning_rate": 1.1660628019323672e-05,
      "loss": 0.004,
      "step": 6350
    },
    {
      "epoch": 2.318840579710145,
      "grad_norm": 0.010303863324224949,
      "learning_rate": 1.1358695652173914e-05,
      "loss": 0.0059,
      "step": 6400
    },
    {
      "epoch": 2.3369565217391304,
      "grad_norm": 0.05642867088317871,
      "learning_rate": 1.1056763285024155e-05,
      "loss": 0.0045,
      "step": 6450
    },
    {
      "epoch": 2.355072463768116,
      "grad_norm": 0.002838830929249525,
      "learning_rate": 1.0754830917874397e-05,
      "loss": 0.0044,
      "step": 6500
    },
    {
      "epoch": 2.3731884057971016,
      "grad_norm": 0.05507192388176918,
      "learning_rate": 1.0452898550724638e-05,
      "loss": 0.005,
      "step": 6550
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 0.014766698703169823,
      "learning_rate": 1.015096618357488e-05,
      "loss": 0.0038,
      "step": 6600
    },
    {
      "epoch": 2.4094202898550723,
      "grad_norm": 0.00044307319330982864,
      "learning_rate": 9.84903381642512e-06,
      "loss": 0.0053,
      "step": 6650
    },
    {
      "epoch": 2.427536231884058,
      "grad_norm": 0.14667287468910217,
      "learning_rate": 9.547101449275362e-06,
      "loss": 0.0041,
      "step": 6700
    },
    {
      "epoch": 2.4456521739130435,
      "grad_norm": 0.0019775540567934513,
      "learning_rate": 9.245169082125605e-06,
      "loss": 0.0039,
      "step": 6750
    },
    {
      "epoch": 2.463768115942029,
      "grad_norm": 0.009348331950604916,
      "learning_rate": 8.943236714975847e-06,
      "loss": 0.0053,
      "step": 6800
    },
    {
      "epoch": 2.4818840579710146,
      "grad_norm": 0.0002691172994673252,
      "learning_rate": 8.641304347826088e-06,
      "loss": 0.0027,
      "step": 6850
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.11118058860301971,
      "learning_rate": 8.33937198067633e-06,
      "loss": 0.0044,
      "step": 6900
    },
    {
      "epoch": 2.5181159420289854,
      "grad_norm": 0.06823856383562088,
      "learning_rate": 8.03743961352657e-06,
      "loss": 0.0043,
      "step": 6950
    },
    {
      "epoch": 2.536231884057971,
      "grad_norm": 0.07358457148075104,
      "learning_rate": 7.735507246376812e-06,
      "loss": 0.0055,
      "step": 7000
    },
    {
      "epoch": 2.5543478260869565,
      "grad_norm": 0.07824483513832092,
      "learning_rate": 7.4335748792270534e-06,
      "loss": 0.0041,
      "step": 7050
    },
    {
      "epoch": 2.572463768115942,
      "grad_norm": 0.10697583109140396,
      "learning_rate": 7.131642512077296e-06,
      "loss": 0.0047,
      "step": 7100
    },
    {
      "epoch": 2.5905797101449277,
      "grad_norm": 0.11679521203041077,
      "learning_rate": 6.829710144927537e-06,
      "loss": 0.0063,
      "step": 7150
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.11067638546228409,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.0038,
      "step": 7200
    },
    {
      "epoch": 2.6268115942028984,
      "grad_norm": 0.015770211815834045,
      "learning_rate": 6.225845410628019e-06,
      "loss": 0.0042,
      "step": 7250
    },
    {
      "epoch": 2.644927536231884,
      "grad_norm": 0.00028191410819999874,
      "learning_rate": 5.923913043478261e-06,
      "loss": 0.0038,
      "step": 7300
    },
    {
      "epoch": 2.6630434782608696,
      "grad_norm": 0.0010724742896854877,
      "learning_rate": 5.621980676328503e-06,
      "loss": 0.004,
      "step": 7350
    },
    {
      "epoch": 2.681159420289855,
      "grad_norm": 0.0017875301418825984,
      "learning_rate": 5.320048309178744e-06,
      "loss": 0.0037,
      "step": 7400
    },
    {
      "epoch": 2.699275362318841,
      "grad_norm": 0.08609507232904434,
      "learning_rate": 5.018115942028985e-06,
      "loss": 0.0044,
      "step": 7450
    },
    {
      "epoch": 2.717391304347826,
      "grad_norm": 0.06982018053531647,
      "learning_rate": 4.716183574879228e-06,
      "loss": 0.0036,
      "step": 7500
    },
    {
      "epoch": 2.7355072463768115,
      "grad_norm": 0.000415743823396042,
      "learning_rate": 4.414251207729469e-06,
      "loss": 0.0044,
      "step": 7550
    },
    {
      "epoch": 2.753623188405797,
      "grad_norm": 0.002639344660565257,
      "learning_rate": 4.11231884057971e-06,
      "loss": 0.0039,
      "step": 7600
    },
    {
      "epoch": 2.7717391304347827,
      "grad_norm": 0.127924844622612,
      "learning_rate": 3.810386473429952e-06,
      "loss": 0.0058,
      "step": 7650
    },
    {
      "epoch": 2.789855072463768,
      "grad_norm": 0.0708126649260521,
      "learning_rate": 3.5084541062801935e-06,
      "loss": 0.0046,
      "step": 7700
    },
    {
      "epoch": 2.807971014492754,
      "grad_norm": 0.058448437601327896,
      "learning_rate": 3.2065217391304353e-06,
      "loss": 0.0069,
      "step": 7750
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 0.11953657120466232,
      "learning_rate": 2.9045893719806763e-06,
      "loss": 0.0044,
      "step": 7800
    },
    {
      "epoch": 2.8442028985507246,
      "grad_norm": 0.10469407588243484,
      "learning_rate": 2.602657004830918e-06,
      "loss": 0.0056,
      "step": 7850
    },
    {
      "epoch": 2.86231884057971,
      "grad_norm": 0.008287273347377777,
      "learning_rate": 2.3007246376811595e-06,
      "loss": 0.0038,
      "step": 7900
    },
    {
      "epoch": 2.880434782608696,
      "grad_norm": 0.038104623556137085,
      "learning_rate": 1.9987922705314013e-06,
      "loss": 0.0052,
      "step": 7950
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 0.08201416581869125,
      "learning_rate": 1.6968599033816427e-06,
      "loss": 0.0065,
      "step": 8000
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 0.17857100069522858,
      "learning_rate": 1.394927536231884e-06,
      "loss": 0.0038,
      "step": 8050
    },
    {
      "epoch": 2.9347826086956523,
      "grad_norm": 0.005361173301935196,
      "learning_rate": 1.0929951690821257e-06,
      "loss": 0.004,
      "step": 8100
    },
    {
      "epoch": 2.9528985507246377,
      "grad_norm": 0.0628347396850586,
      "learning_rate": 7.910628019323673e-07,
      "loss": 0.004,
      "step": 8150
    },
    {
      "epoch": 2.971014492753623,
      "grad_norm": 0.006946441251784563,
      "learning_rate": 4.891304347826088e-07,
      "loss": 0.0041,
      "step": 8200
    },
    {
      "epoch": 2.9891304347826084,
      "grad_norm": 0.1677428036928177,
      "learning_rate": 1.8719806763285025e-07,
      "loss": 0.0047,
      "step": 8250
    }
  ],
  "logging_steps": 50,
  "max_steps": 8280,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2182613121146880.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
